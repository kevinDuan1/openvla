{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForVision2Seq, AutoProcessor, BitsAndBytesConfig\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os \n",
    "\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoProcessor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load Processor & VLA\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# path = '/cluster/nvme9a/dzk/'\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m processor \u001b[38;5;241m=\u001b[39m \u001b[43mAutoProcessor\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenvla/openvla-7b\u001b[39m\u001b[38;5;124m\"\u001b[39m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m vla \u001b[38;5;241m=\u001b[39m AutoModelForVision2Seq\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenvla/openvla-7b\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      6\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Grab image input & format prompt\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# image: Image.Image = get_from_camera(...)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# open a image file\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoProcessor' is not defined"
     ]
    }
   ],
   "source": [
    "# Load Processor & VLA\n",
    "# path = '/cluster/nvme9a/dzk/'\n",
    "processor = AutoProcessor.from_pretrained(\"openvla/openvla-7b\", trust_remote_code=True)\n",
    "vla = AutoModelForVision2Seq.from_pretrained(\n",
    "    \"openvla/openvla-7b\", \n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",  # [Optional] Requires `flash_attn`\n",
    "    low_cpu_mem_usage=True, \n",
    "    trust_remote_code=True,\n",
    ").to(device)\n",
    "\n",
    "# Grab image input & format prompt\n",
    "# image: Image.Image = get_from_camera(...)\n",
    "# open a image file\n",
    "image = Image.open(\"test.png\")\n",
    "instruction = \"put eggplant into pot\"\n",
    "prompt = f\"In: What action should the robot take to {instruction}?\\nOut:\"\n",
    "\n",
    "# Predict Action (7-DoF; un-normalize for BridgeData V2)\n",
    "inputs = processor(prompt, image).to(device, dtype=torch.bfloat16)\n",
    "action = vla.predict_action(**inputs, unnorm_key=\"bridge_orig\", do_sample=False)\n",
    "# Execute...\n",
    "# robot.act(action, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-11-04 14:16:38 74110:74110 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-11-04 14:16:38 74110:74110 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-11-04 14:16:38 74110:74110 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "# from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "# === BFLOAT16 MODE ===\n",
    "inputs = processor(prompt, image).to(device, dtype=torch.bfloat16)\n",
    "# inputs[\"input_ids\"] = inputs[\"input_ids\"][:, 1:]\n",
    "\n",
    "# Run OpenVLA Inference\n",
    "torch.manual_seed(0)\n",
    "def trace_handler(prof):\n",
    "    # print(prof.key_averages().table(\n",
    "    #     sort_by=\"self_cuda_time_total\", row_limit=-1))\n",
    "    prof.export_chrome_trace(\"tmp/test_trace_\" + str(prof.step_num) + \".json\")\n",
    "\n",
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "        torch.profiler.ProfilerActivity.CUDA,\n",
    "    ],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=1),\n",
    "    on_trace_ready=trace_handler,\n",
    "    with_stack=True,\n",
    "    profile_memory=True,\n",
    "    with_flops = True\n",
    "    ) as p:\n",
    "        for iter in range(3):\n",
    "            action = vla.predict_action(**inputs, unnorm_key=\"bridge_orig\", do_sample=False)\n",
    "            p.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inference time:  167.4547607421875\n",
      "Std:  1.8540565967559814\n"
     ]
    }
   ],
   "source": [
    "# profile latecy with cuda event\n",
    "# calculate 10 runs and get the average inference and std with torch events\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "times = []\n",
    "for i in range(10):\n",
    "    start.record()\n",
    "    action = vla.predict_action(**inputs, unnorm_key=\"bridge_orig\", do_sample=False)\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    times.append(start.elapsed_time(end))\n",
    "print(\"Average inference time: \", sum(times)/len(times))\n",
    "print(\"Std: \", torch.tensor(times).std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 1                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  14405 MiB |  14692 MiB |  89785 MiB |  75380 MiB |\n",
      "|       from large pool |  14401 MiB |  14688 MiB |  82197 MiB |  67795 MiB |\n",
      "|       from small pool |      3 MiB |      7 MiB |   7588 MiB |   7584 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  14405 MiB |  14692 MiB |  89785 MiB |  75380 MiB |\n",
      "|       from large pool |  14401 MiB |  14688 MiB |  82197 MiB |  67795 MiB |\n",
      "|       from small pool |      3 MiB |      7 MiB |   7588 MiB |   7584 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |  14392 MiB |  14674 MiB |  88027 MiB |  73635 MiB |\n",
      "|       from large pool |  14388 MiB |  14670 MiB |  80453 MiB |  66065 MiB |\n",
      "|       from small pool |      3 MiB |      7 MiB |   7573 MiB |   7570 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  14756 MiB |  14756 MiB |  14756 MiB |      0 B   |\n",
      "|       from large pool |  14746 MiB |  14746 MiB |  14746 MiB |      0 B   |\n",
      "|       from small pool |     10 MiB |     10 MiB |     10 MiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  55942 KiB | 125830 KiB |  95352 MiB |  95298 MiB |\n",
      "|       from large pool |  53640 KiB | 123656 KiB |  87030 MiB |  86977 MiB |\n",
      "|       from small pool |   2302 KiB |   3825 KiB |   8322 MiB |   8320 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |    1019    |    1170    |  159852    |  158833    |\n",
      "|       from large pool |     441    |     569    |   23331    |   22890    |\n",
      "|       from small pool |     578    |     602    |  136521    |  135943    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |    1019    |    1170    |  159852    |  158833    |\n",
      "|       from large pool |     441    |     569    |   23331    |   22890    |\n",
      "|       from small pool |     578    |     602    |  136521    |  135943    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     322    |     322    |     322    |       0    |\n",
      "|       from large pool |     317    |     317    |     317    |       0    |\n",
      "|       from small pool |       5    |       5    |       5    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      28    |      43    |   74524    |   74496    |\n",
      "|       from large pool |      25    |      36    |   13825    |   13800    |\n",
      "|       from small pool |       3    |      12    |   60699    |   60696    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#profile memroy with torch\n",
    "print(torch.cuda.memory_summary(device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
